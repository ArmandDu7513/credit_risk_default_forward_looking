################################   Packages    ###################################
import streamlit as st
from PIL import Image
import pandas as pd
import numpy as np
from streamlit import session_state

import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.tsa.stattools import kpss
from arch.unitroot import PhillipsPerron
from statsmodels.tsa.stattools import adfuller

import time

from sklearn.preprocessing import StandardScaler
from statsmodels.tsa.seasonal import seasonal_decompose

import matplotlib.pyplot as plt
import seaborn as sns

from scipy.stats import shapiro, kstest
from scipy.stats import kendalltau
from statsmodels.stats.outliers_influence import variance_inflation_factor

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings("ignore")

from functions_module import remove_season, lissage_moyenne_mobile, logit, import_and_series_transformation, import_and_series_transformation_and_graph, drop_trimestrielle_or_annuelle_if_wanted, highlight_variables, highlight_result, highlight_value, ljung_box, show_acf_pacf, AugmenteDickeyFuller_test, PhillipsPerron_test, kpss_test, concat_tests_and_sort, draw_conclusion_stationary, readable_conclusions, newey_west_tests_find_beta, compute_var_lagged, commpute_corr_matrix, choosing_seuil_corr_to_DR, commpute_corr_matrix_var_macro, find_high_corr_pairs


################################   Main Config    ###################################

icon = Image.open("pictures/nexialog_icon.png")

st.set_page_config(
    page_title="Projet Nexialog - Application PD Forward Looking",
    page_icon=icon,

)



# Create a sidebar
st.sidebar.title("Projet Nexialog - Application PD Forward Looking")

# Create a dropdown menu for navigation
page_options = ["I - Transformation des sÃ©ries temporelles","II - Variables MacroÃ©conomiques : StationnaritÃ©", "III - Taux de DÃ©faut : StationnaritÃ©", "IV - CorrÃ©lation des variables", "V - PrÃ©voir DRt"]
selected_page = st.sidebar.selectbox("Chapitre...", page_options)

# create global variable : the dataframe to begin with
macro_base = pd.read_excel("Bases/variables_macroeconomiques.xlsx").set_index("Date")

# Create the pages

######################################################################################
####################################   PAGE 1   ######################################
######################################################################################

if selected_page == "I - Transformation des sÃ©ries temporelles":

    col1, col2 = st.columns(2)
    with col1:
        st.image('pictures/nexialog1.jpg')
    with col2:
        st.image('pictures/paris1.jpg')


    st.title("I - Transformation des sÃ©ries temporelles")
    st.header("PrÃ©sentation des sÃ©ries brutes")
    st.write("Nous disposons de 5 sÃ©ries macro-Ã©conomiques et du taux de dÃ©faut. Les sÃ©ries macro-Ã©conomiques sont des sÃ©ries brutes qui nÃ©cessitent de subir des transformations avant que l'on puisse les utiliser dans une quelconque modÃ©lisation. D'abord, on peut montrer Ã  quoi ressemblent les sÃ©ries macro. Elles sont exprimÃ©es en unitÃ©s de mesures diffÃ©rentes (â‚¬, %...) /n Par ailleurs, on peut dÃ¨s maintenant analyser les chocs et les tendances des sÃ©ries")
    st.image('graphs/ts_brutes.png', width=750)

    list_col_transformed_columns = macro_base.add_suffix('_ann').columns.tolist() + macro_base.add_suffix('_tri').columns.tolist()

    st.header("Choix des transformations")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.header('NaN')
        drop_na = st.radio("Voulez-vous retirer les valeurs manquantes en dÃ©but et en fin de sÃ©rie liÃ©es au taux de dÃ©faut ?",
        ('Non', 'Oui'))
    with col2:
        st.header('Logit')
        logit_choix = st.radio("Voulez-vous appliquer une transformation sur le taux de dÃ©faut ?",
        ('Non', 'Oui'))
    with col3:
        st.header('Lissage')
        list_col_lissage = st.multiselect(
        "Quelles sont les variables que vous dÃ©sirez rectifier en lissant les derniÃ¨res observations (de sorte Ã  retirer l'effet COVID, qui peut tromper la modÃ©lisation)?",
        list_col_transformed_columns, default = ['RGDP_ann', 'RGDP_tri'])
        #st.write('On applique un lissage des derniÃ¨res observations sur :', list_col_lissage)
    with col4:
        st.header('SaisonnalitÃ©')
        list_col_saison = st.multiselect(
        'Quelles sont les variables que vous dÃ©sirez rectifier en estimant puis en retirant la saisonnalitÃ©?',
        macro_base.columns, default = ['HICP'])
        #st.write('On retire la saisonnalitÃ© de :', list_col_saison)

    col1, col2 = st.columns([1,4])

    # Selection de la variable Ã  montrer sur le graphique comparant la variable au taux de dÃ©faut &  Realisation du dataframe selon les transformations demandÃ©e
    with col1:
        variable_to_show = st.radio("On montre le graphique du taux de dÃ©faut comparÃ© Ã  la variable... : ", list_col_transformed_columns, key='radio_graph')
    with col2:
        macro = import_and_series_transformation_and_graph(drop_na, list_col_saison, list_col_lissage, logit_choix,  variable_to_show )
    
    st.header("Choix des types de variables")

    choix_des_variables = st.radio('Voulez-vous retirer un certain type de variables ? Vous pouvez retirer les transformations par variation trimestrielles pour ne garder que les variables qui reprÃ©sentent les variations annuelles. Inversement, vous pouvez choisir des garder les variables issues des variations annuelles, et retirer les autres. Nous conseillons de garder les deux types. Vous choisissez de garder... :', 
                       ('Les deux variations', 'Trimestrielles', 'Annuelles'))
    macro_kept = drop_trimestrielle_or_annuelle_if_wanted(macro, choix_des_variables)

    st.session_state.macro_kept = macro_kept
    show_df = st.checkbox('Voulez-vous voir le dataframe ?')
    if show_df:
        st.dataframe(st.session_state.macro_kept)







######################################################################################
####################################   PAGE 2   ######################################
######################################################################################

elif selected_page == "II - Variables MacroÃ©conomiques : StationnaritÃ©":
    
    st.title("II - Variables MacroÃ©conomiques : StationnaritÃ©")
    st.header("PrÃ©sentation des Tests")
    st.write("La non-stationnaritÃ© a des consÃ©quences fondamentales sur le plan Ã©conomÃ©trique. En prÃ©sence d'une racine unitaire, les propriÃ©tÃ©s asymptotiques usuelles des estimateurs ne sont plus valables et il est nÃ©cessaire de dÃ©velopper une thÃ©orie asymptotique particuliÃ¨re.  \n Les variables non stationnaires sont exclus de l'Ã©tude.")
    st.write("ADF (Augmented Dickey Fuller)")
    st.write("On met en Å“uvre la rÃ©gression âˆ†ğ‘‹_ğ‘¡ = ğ›¾_0+ğœ™_1 ğ‘‹_(ğ‘¡âˆ’1)+ğ‘¢_ğ‘¡. C'est un test unilatÃ©ral qui a pour hypothÃ¨sesÂ : \n H_0 : racine unitaire donc -> non-stationnaritÃ©. \n H_1 : pas de racine unitaire -> stationnaritÃ©")
    st.write("KPSS (Kwiatkowski-Phillips-Schmidt-Shin)")
    st.write("Le test de KPSS dÃ©termine si une sÃ©rie chronologique est stationnaire autour dâ€™une tendance moyenne ou linÃ©aire, ou non stationnaire en raison de la prÃ©sence dâ€™une racine unitaire.")
    st.write("Le test KPSS est basÃ© sur une rÃ©gression linÃ©aire. Il dÃ©compose une sÃ©rie en trois parties : une tendance dÃ©terministe (ğ›½ğ‘¡), une marche alÃ©atoire (ğ›¼) et une erreur stationnaire (ğœ€_ğ‘¡), avec l'Ã©quation de rÃ©gression :")
    st.write("ğ‘‹_ğ‘¡ = âˆ…ğ‘‹_(ğ‘¡âˆ’1)+ ğ›¼ + ğ›½ğ‘¡ + ğœ€_ğ‘¡.")
    st.write("Au final on teste : (ğ»0 :ğ¿ğ‘ ğ‘ Ã©ğ‘Ÿğ‘–ğ‘’ ğ‘’ğ‘ ğ‘¡ ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘›ğ‘ğ‘–ğ‘Ÿğ‘’ ğ»1 :ğ¿ğ‘ ğ‘ Ã©ğ‘Ÿğ‘–ğ‘’ ğ‘›' ğ‘’ğ‘ ğ‘¡ ğ‘ğ‘ğ‘  ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘›ğ‘ğ‘–ğ‘Ÿğ‘’)")
    st.write("Phillips Perron")
    st.write("SDFGSTGSH")
    st.write("H0 ... H1 ...")

    show_df = st.checkbox('On rÃ©cupÃ¨re le dataframe dÃ©finit dans la partie I. Le voici :')
    macro = st.session_state.macro_kept
    if show_df:
        st.dataframe(macro)

    st.header("Test sur les rÃ©sidus : Test de Ljung-Box")
    
    lj_b = ljung_box(macro, 'Yes')
    st.dataframe(lj_b.style.applymap(highlight_value, subset=['RÃ©sultat']))


    st.header('Analyse graphique : ACF et PACF')
    variable_choisie = st.selectbox(
    "Quelle est la variable que vous souhaitez analyser avec son ACF/PACF?",
    macro.drop('td', axis=1).columns)
    st.write('On observe les graphiques pour :', variable_choisie)

    show_acf_pacf(macro, variable_choisie)


    st.header('Tests de stationnaritÃ© : KPSS, Philips Perron, Augmented Dickey Fuller')

    st.write("Chaque test a une construction diffÃ©rente. On peut tester plusieurs hypothÃ¨ses. Pour KPSS on peut choisir de tester la stationnaritÃ©, de chaque sÃ©rie, en supposant qu'elle admet une constante. On peut sinon admettre qu'elle contient un trend en plus d'une constante. On propose aussi de tester ces deux hypothÃ¨ses simultanÃ©ment /n Usuellement, on choisit de garder le moins d'attributs dÃ©terministes possible : Pour KPPS on prend souvent 'c', pour les autres tests on prend 'n' ('none').")

    st.header('Choix des hypothÃ¨ses')

    col1, col2 = st.columns([1, 2])

    with col1:
        regression_type_kpss = st.selectbox(
        "Choix de l'hypothÃ¨se testÃ©e, choix du Type de rÃ©gression du test KPSS:",
        ('c', 'ct', 'c_et_ct'))
        # st.write("On teste la stationnaritÃ© pour l'hypothÃ¨se (ou les hypothÃ¨ses) : ", regression_type_kpss)


    with col2:
        regression_type_pp = st.selectbox(
        "Choix de l'hypothÃ¨se testÃ©e, choix du Type de rÃ©gression pour les tests ADF et Philips Perron:",
        ('n', 'c', 'ct', 'n_et_c', 'n_et_ct', 'c_et_ct', 'all'))
        # st.write("On teste la stationnaritÃ© pour l'hypothÃ¨se (ou les hypothÃ¨ses) : ", regression_type_pp)

    st.header('RÃ©sultats des tests')

    col1, col2 , col3= st.columns(3)

    with col1:
        st.write('Test Kwiatkowski-Phillips-Schmidt-Shin')
        if regression_type_kpss == 'c':
            results_kpss = kpss_test(macro.drop('td', axis=1).dropna(), regression='c')
        elif regression_type_kpss == 'ct':
            results_kpss = kpss_test(macro.drop('td', axis=1).dropna(), regression='ct')
        else : # 'c_et_ct'
            results_c = kpss_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_ct = kpss_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_kpss = pd.concat([results_c, results_ct], ignore_index=True)
        st.dataframe(results_kpss.style.applymap(highlight_result, subset=['RÃ©sultat']))

    with col2:
        st.write('Test Philips Perron')
        if regression_type_pp == 'n':
            results_pp = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='n')
        elif regression_type_pp == 'c':
            results_pp = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='c')
        elif regression_type_pp == 'ct':
            results_pp = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='ct')
        elif regression_type_pp == 'n_et_c':
            results_n = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_c = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_pp = pd.concat([results_n, results_c], ignore_index=True)
        elif regression_type_pp == 'n_et_ct':
            results_n = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_ct = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_pp = pd.concat([results_n, results_ct], ignore_index=True)
        elif regression_type_pp == 'c_et_ct':
            results_c = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_ct = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_pp = pd.concat([results_c, results_ct], ignore_index=True)
        else:
            results_n = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_c = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_ct = PhillipsPerron_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_pp = pd.concat([results_n, results_c, results_ct], ignore_index=True)
        st.dataframe(results_pp.style.applymap(highlight_result, subset=['RÃ©sultat']))

    with col3:
        st.write('Test Augmented Dickey Fuller')
        if regression_type_pp == 'n':
            results_adf = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='n')
        elif regression_type_pp == 'c':
            results_adf = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='c')
        elif regression_type_pp == 'ct':
            results_adf = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='ct')
        elif regression_type_pp == 'n_et_c':
            results_n = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_c = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_adf = pd.concat([results_n, results_c], ignore_index=True)
        elif regression_type_pp == 'n_et_ct':
            results_n = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_ct = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_adf = pd.concat([results_n, results_ct], ignore_index=True)
        elif regression_type_pp == 'c_et_ct':
            results_c = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_ct = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_adf = pd.concat([results_c, results_ct], ignore_index=True)
        else:
            results_n = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='n')
            results_c = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='c')
            results_ct = AugmenteDickeyFuller_test(macro.drop('td', axis=1).dropna(), regression='ct')
            results_adf = pd.concat([results_n, results_c, results_ct], ignore_index=True)
        st.dataframe(results_adf.style.applymap(highlight_result, subset=['RÃ©sultat']))

    st.header('Conclusion')
    st.write('On va concatÃ©ner les rÃ©sultats des 3 tests afin de compter le nombre de tests qui concluent en faveur de la stationnaritÃ© par rapport Ã  ceux qui concluent en dÃ©faveur de la stationnaritÃ©. On exprique ce rÃ©sultat en Pourcentage : plus il est Ã©levÃ©, plus il est probable que la sÃ©rie soit stationnaire.')


    resultats_des_tests = concat_tests_and_sort(results_kpss, results_pp, results_adf)
    nb_variables_studies = len(resultats_des_tests['Variable'].unique())
    conclusions = draw_conclusion_stationary(resultats_des_tests, nb_variables_studies)
    conclusions_readable = readable_conclusions(conclusions)
    st.dataframe(conclusions_readable.style.applymap(highlight_result, subset=['DÃ©cision Finale']))

    st.write("Quand plus de 50% des tests concluent que la sÃ©rie est stationnaire, on penche en faveur de la stationnaritÃ©. Sinon, on dÃ©cide de mettre cette variable, elle ne sera pas utilisÃ©e dans les prochaines Ã©tapes, car elle est inutilisable pour l'Ã©tape de la modÃ©lisation.")

    list_var_stationary = conclusions_readable[conclusions_readable['DÃ©cision Finale']=='Stationnaire']['Variable'].unique().tolist()

    show_df_out = st.checkbox('Le dataframe en output selon les rÃ©sultats des tests est le suivant:')
    
    if show_df_out:
        st.dataframe(macro[list_var_stationary+ ['td']])
    
    st.session_state.macro_stationary = macro[list_var_stationary+ ['td']]

    st.write('Maintenant que nous avons dÃ©terminÃ© quelles sont les variables macroÃ©conomiques qui sont stationnaires, on doit Ã©tudier la stationnaritÃ© du taux de dÃ©faut.')

######################################################################################
####################################   PAGE 3   ######################################
######################################################################################

elif selected_page == "III - Taux de DÃ©faut : StationnaritÃ©":
 
    st.title("III - Taux de DÃ©faut : StationnaritÃ©")

    macro = st.session_state.macro_kept

    st.header('Analyse graphique : ACF et PACF')
    td_serie = pd.DataFrame(macro['td']).dropna()
    show_acf_pacf(td_serie, 'td')

    st.header('Tests de stationnaritÃ© : Ljung-Box, KPSS, Philips Perron, Augmented Dickey Fuller')

    lj_b = ljung_box(td_serie, 'No')
    st.dataframe(lj_b.style.applymap(highlight_value, subset=['RÃ©sultat']))


    results_KPSS_c = kpss_test(td_serie, regression='c')
    results_PP_c = PhillipsPerron_test(td_serie,  regression='c')
    results_ADF_c = AugmenteDickeyFuller_test(td_serie, regression='c')
    results_DR = pd.concat([results_KPSS_c, results_PP_c, results_ADF_c], ignore_index=True)
    st.dataframe(results_DR.style.applymap(highlight_result, subset=['RÃ©sultat']))
    st.write("On voit rapidement entre les graphiques et les tests, que le taux de dÃ©faut n'est absolument pas stationnaire. On va dont passer par la diffÃ©renciation partielle.")

    st.header('DiffÃ©renciation partielle du Taux de dÃ©faut')
    st.write("Ici on a compris que le taux de dÃ©faut n'Ã©tait pas stationnaire. Automatiquement, on pense Ã  appliquer la diffÃ©rence premiÃ¨re et regarder Ã  nouveau s'il est stationnaire. Cependant diffÃ©rencier le taux de dÃ©faut est une mauvaise pratique. On prÃ©fÃ¨re alors regarder pour quel coefficient Beta, la sÃ©rie de DiffÃ©rence Partielle est stationnaire. /n Ici on teste l'Ã©quation : DRt - Beta * DRt-1. Et on en retire les Betas pour lesquels l'Ã©quation est stationnaire")

    col1, col2 , col3= st.columns(3)

    with col1:
        kpss_beta = newey_west_tests_find_beta(macro, 'KPSS')
    with col2:
        pp_beta = newey_west_tests_find_beta(macro, 'PP')
    with col3:
        adf_beta = newey_west_tests_find_beta(macro, 'ADF')
    
    st.write("exemple de dataframe en sortie : permet de donner les valeurs exactes des betas")
    st.dataframe(adf_beta)

    st.header("Choix de l'intervalle du Beta")
    st.write("Ainsi, on peut choisir un intervalle pour le coefficient. On estimera plustard les modÃ¨les pour prÃ©dire le taux de dÃ©faut, et ceux-ci devront vÃ©rifier la condition Ã©noncÃ© par l'intervalle ici dÃ©clarÃ©.")

    beta_intervalle = st.slider(
    "Vous pouvez sÃ©lectionner l'intervalle que vous juger juste: ",
    0.0, 1.0, (0.05, 0.95))
    st.write('Valeurs choisies:', beta_intervalle)
    st.session_state.beta_intervalle = beta_intervalle


######################################################################################
####################################   PAGE 4   ######################################
######################################################################################

elif selected_page == "IV - CorrÃ©lation des variables":
 
    st.title("IV - CorrÃ©lation des variables")
    macro_var_chosen = st.session_state.macro_kept

    st.title("Calcul des variables explicatives retardÃ©es")
    st.write("On a maintenant seulement les variables stationnaires. On peut alors choisir de prendre les 'lags'pour crÃ©er des retards des variables. On laisse le choix Ã  l'utilisateur du nombre de retards qu'on accorde aux variables. On peut mettre un nombre de retards diffÃ©rent pour les variables avec variation trimestrielle et avec variation annuelle. Il faut faire attention car plus on ajoute de retards, plus on crÃ©e des variables manquantes en dÃ©but de pÃ©riode. Les variables avec variation annuelle ont dÃ©jÃ  plusieurs valeurs manquantes en dÃ©but de pÃ©riode. C'est pourquoi on conseille de bien garder un nombre de retards plus faible pour les varibles en variations annuelles.")

    default_value_ann = 2
    default_value_tri = 5

    number_lag_ann = st.number_input('Choisir un nombre de retards pour les variables annuelles',min_value = 0, max_value = 8, value = default_value_ann)
    st.write('Nombre de retards maximum :', number_lag_ann)

    number_lag_tri = st.number_input('Choisir un nombre de retards pour les variables trimestrielles',min_value = 0, max_value = 8, value = default_value_tri)
    st.write('Nombre de retards maximum :', number_lag_tri)
    number_lag_td=1
    macro_lagged = compute_var_lagged(st.session_state.macro_kept, number_lag_ann, number_lag_tri, number_lag_td)
    macro_lagged_for_model = macro_lagged.copy()
    show_datafr = st.checkbox('Voir le dataframe, avec les variables retardÃ©es.')
    if show_datafr:
        st.dataframe(macro_lagged)

    show_list = st.checkbox('Voir la liste des variables, avec retard.')
    if show_list:
        st.write(macro_lagged.columns)

    st.header("CorrÃ©lation : Taux de dÃ©faut versus Variables macro")

    corr_df = commpute_corr_matrix(macro_lagged)
    # On se focalise sur les correlations concernant le taux de dÃ©faut
    df_var_corr_to_DR = pd.DataFrame(corr_df['td']).rename(columns={'td': 'Kendall Correlations'}).sort_values(by=['Kendall Correlations']).drop('td',axis=0)
    #peu importe le sens des signes, on cherche surtout Ã  avoir les variables qui sont corrÃ©lÃ©es avec le taux de dÃ©faut : donc on prend la valeur absolue
    df_var_corr_to_DR['Kendall Correlations'] = df_var_corr_to_DR['Kendall Correlations'].abs()
    df_var_corr_to_DR = df_var_corr_to_DR.sort_values(by=['Kendall Correlations'], ascending=False)
    
    show_datafr_corr_td = st.checkbox('Voir les corrÃ©lations des variables (corrÃ©lations absolues) avec le taux de dÃ©faut.')
    if show_datafr_corr_td:
        st.dataframe(df_var_corr_to_DR)

    default_value_threshold = 0.15
    number_threshold = st.number_input('Choisir un seuil minimal de corrÃ©lation pour utilser la variable',min_value = 0.00, max_value = 1.00, value = default_value_threshold)
    st.write('Seuil =', number_threshold)

    list_var_in_model = choosing_seuil_corr_to_DR(df_var_corr_to_DR, number_threshold)
    
    show_list_var_corr = st.checkbox("Voir la liste des variables macroÃ©conomiques qu'on souhaite garder car elles sont assez corrÃ©lÃ©es avec le taux de dÃ©faut")
    if show_list_var_corr:
        st.write(sorted(list_var_in_model))

    ######################################################
    st.header("CorrÃ©lation : Les variables macro entre elles")
    st.write(
            "A travers l'Ã©tude des corrÃ©lations, on peut anticiper une trop forte corrÃ©lation entre des variables. Surtout lorsqu'il s'agit de la mÃªme variable, avec un retard diffÃ©rent. On propose de retirer manuellement des variables")
    st.write(
            "D'abord, on montre Ã  gauche les corrÃ©lations de toutes les variables. Puis sur la partie de droite on laisse la possibilitÃ© de retirer des varaibles, pour que le seuil de corrÃ©lation indiquÃ© ne soit pas dÃ©passÃ©.")
            
    macro_lagged_seuil = macro_lagged.copy()
    macro_lagged_for_corr = macro_lagged.copy()

    col1, col2 = st.columns(2)
    with col1:
        st.subheader('CorrÃ©lation : Point de dÃ©part')
        st.write(" ")
        corr_df_macro = commpute_corr_matrix_var_macro(macro_lagged, sorted(list_var_in_model))
        show_list_var_corr_df = st.checkbox("Voir le dataframe avec toutes les varaibles, que les corrÃ©lations soient Ã©levÃ©es ou non.")
        if show_list_var_corr_df:
            st.dataframe(corr_df_macro)
        fig, ax = plt.subplots()
        sns.heatmap(corr_df_macro.astype(float), cmap='coolwarm', center=0, annot=False)
        st.pyplot(fig)


    with col2:
        st.subheader('Choix du seuil')
        # on dÃ©finit le seuil de corrÃ©lation.
        default_seuil = 0.6
        number_seuil = st.number_input('',min_value = 0.00, max_value = 1.00, value = default_seuil)

        first_elements_variables = [t[0] for t in find_high_corr_pairs(corr_df_macro, number_seuil)]
        all_elements_variables = list(set(first_elements_variables))

        macro_lagged_for_corr = macro_lagged_for_corr[list_var_in_model].drop(all_elements_variables, axis=1)

        corr_df_for_corr = commpute_corr_matrix_var_macro(macro_lagged_for_corr, sorted(macro_lagged_for_corr.columns))
    
        fig, ax = plt.subplots()
        sns.heatmap(corr_df_for_corr.astype(float), cmap='coolwarm', center=0, annot=False)
        st.pyplot(fig)
    
    show_df_corr_all = st.checkbox('Dataframe rassemblant toutes les corrÃ©lation de toutes les variables')
    if show_df_corr_all:
            st.dataframe(macro_lagged[corr_df_for_corr.columns])

    #show_df = st.checkbox('Voulez-vous voir le dataframe prÃªt pour la modÃ©lisation')
    #if show_df:
    #    st.dataframe(macro_lagged_for_model[list_corr_df_macro].dropna())
    #st.session_state.macro_for_model = macro_lagged_for_model[list_corr_df_macro].dropna()


######################################################################################
####################################   PAGE 5   ######################################
######################################################################################
elif selected_page == "V - PrÃ©voir DRt":
 
    st.title("V - PrÃ©voir DRt")
    macro_model = st.session_state.macro_for_model